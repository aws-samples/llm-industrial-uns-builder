{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of AWS IoT Sitewise Assets at scale\n",
    "\n",
    "### ‚õ≥ Objective\n",
    "To work with a large number of assets or asset models, use bulk operations to bulk import and export resources to a different location. In this Notebook we will do the following\n",
    "1. Execute **Metedata Bulk Import:** You have a data file that defines assets and asset models and upload it in an Amazon S3 bucket, and use bulk import to create or update them in AWS IoT SiteWise. \n",
    "2. **Shopfloor Connectivity Framwork** Deployment : You will deploy Shopfloor Connectivity Framework (SFC) and also configure it to send data to the asstes you have created in the previous step.\n",
    "3. **GenerativeAI** Playground : You will execute the **Metedata Bulk Import** agian but this time you will use the artefacts and configuration files created in the previous Notebook.\n",
    "4. **Visualisation:** You will visualise the assets you have created using AWS IoT Sitewise Monitor. You will learn how to create the Portal programatically and then create dashboards.\n",
    "\n",
    "### üóùÔ∏è Key concept refreshers\n",
    "\n",
    "Before we dive into the practical application, let's quickly review the essential concepts:\n",
    "\n",
    "1. [**AWS IoT SiteWise Bulk Import :**](https://docs.aws.amazon.com/iot-sitewise/latest/userguide/bulk-operations-assets-and-models.html) AWS IoT SiteWise Bulk Import enables the large-scale ingestion of historical and real-time equipment data into SiteWise for analysis and monitoring. It simplifies the import process by supporting structured data ingestion in bulk, especially useful for legacy systems. Learn more about bulk import.\n",
    "2. **Shopfloor Connectivity :** Shopfloor Connectivity connects factory-floor equipment (e.g., machines, sensors) to digital systems for real-time data collection and monitoring. This integration, using protocols like OPC-UA, Siemens S7 and Modbus, improves operational visibility and supports predictive maintenance.\n",
    "3. [**AWS IoT SiteWise Monitor :**](https://docs.aws.amazon.com/iot-sitewise/latest/userguide/bulk-operations-assets-and-models.html) AWS IoT SiteWise Monitor is a tool that allows users to create and share real-time dashboards for monitoring industrial data. It provides a no-code interface for easy dashboard customization and secure access for team members.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>üí°</b> You perform bulk operations in AWS IoT SiteWise by calling operations in the AWS IoT TwinMaker API. You can do this without setting up AWS IoT TwinMaker or creating an AWS IoT TwinMaker workspace. All you need is an Amazon S3 bucket where you can place your AWS IoT SiteWise content.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### &#x1F4DA; Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture config_logs\n",
    "!py -m pip install pickleshare\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from ec2_metadata import ec2_metadata\n",
    "from sitewise_helpers import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#x2699; Configuration for AWS IoT Sitewise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aws_account = boto3.client('sts').get_caller_identity()['Account']\n",
    "aws_region = ec2_metadata.region\n",
    "aws_stack_name = 'uns-scale-connectivity-workshop'\n",
    "twinmakerclient = boto3.client('iottwinmaker', region_name=aws_region)\n",
    "s3client = boto3.client('s3')\n",
    "bucketname = f'reinvent-{aws_stack_name}-{aws_account}-{aws_region}'  \n",
    "roleArn = f'arn:aws:iam::{aws_account}:role/data_import_role_workshop-{aws_stack_name}'\n",
    "print(f'aws_region: {aws_region}')\n",
    "print(f'aws_account: {aws_account}')\n",
    "print (f'aws_bucketname: {bucketname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. AWS IoT Sitewise Bulk Operations to create assets and models at scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<span style=\"font-size: 1.5em;\">üí°</span> In the last <em>Notebook 02</em>, we generated three configuration files. Generally, any Large language Model (LLM) response needs to be tested and quality checked against a desired outcome before deployment in Production. So before we start working with the files generated by GenAI, let's first try to understand how bulk import works with a pre-configured schema.</div>\n",
    "\n",
    "In this step, we will use <span style=\"font-family: monospace;\">complete_assets_models_definitions.json</span> where the following things are configured into the AWS IoT SiteWise schema\n",
    "1. Asset Models\n",
    "2. Asset Models Properties and Metrics\n",
    "3. Assets\n",
    "4. Hierarchy Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create Bulk Import Job for AWS IoT Sitewise\n",
    "\n",
    "To run a bulk import job is a three step process :\n",
    "1. Preparing the schema file to import\n",
    "2. Upload the prepared file to Amazon S3\n",
    "3. Execute Bulk import Job\n",
    "\n",
    "In the next cell, we create a function definition to execute bulk import that takes the schema definition file as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucnction definition to execute a meta data bulk import\n",
    "def meta_data_import(filename):\n",
    "    os.chdir('C://Users//Administrator//Documents//jupyter-notebook')\n",
    "    prefix = 'data/'\n",
    "\n",
    "    # 1. Upload the config files to S3\n",
    "    s3client.upload_file(filename, bucketname, prefix + filename)\n",
    "    print(\"Uploaded \" + filename + \" to \" + bucketname + \" with prefix \" + prefix)\n",
    "\n",
    "    job_id = f'Bulk_Import_ID_{int(datetime.now().timestamp())}'\n",
    "    s3_location = f'arn:aws:s3:::{bucketname}/{prefix}{filename}'\n",
    "    \n",
    "    # 2. Execute Bulk Import API Call to AWS IoT Sitewise\n",
    "    print(job_id)\n",
    "    twinmakerresponse = twinmakerclient.create_metadata_transfer_job(\n",
    "        metadataTransferJobId = job_id,\n",
    "        sources=[{\n",
    "            'type': 's3',\n",
    "            's3Configuration': {\n",
    "            'location': s3_location\n",
    "                }\n",
    "            }],\n",
    "        destination={\n",
    "                'type': 'iotsitewise'\n",
    "            }\n",
    "        )\n",
    "    return job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will call this function, where we will pass a preconfigured schema with AWS IoT Sitewise asset models, assets and assets hierarchy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call to execute meta data bulk import\n",
    "sitewise_schema = \"complete_asset_models_definition.json\"\n",
    "import_job_id = meta_data_import(sitewise_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<span style=\"font-size: 1.5em;\">üìã</span> As you wait for the next execution to complete, go through the <span style=\"font-family: monospace;\">complete_asset_models_definition.json</span> template and the response files generated by Amazon Bedrock <em>Notebook 02</em> <ul>\n",
    " <li>What difference do you see ?</li>\n",
    " <li>How similar are they to each other?</li>\n",
    " <li>Are you confident to excute another Bulk import job using the LLM's response ?</li></ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Check Bulk Import Job Progress\n",
    "\n",
    "Before moving ahead we need to wait until the bulk import job is completed. You can check this either on the AWS Console or you can use the status response method offered tou you by AWS IoT Sitewise to check the programatically. In both cases, please wait until the execution is complete!\n",
    "\n",
    "To check the status from this Notebook, please execute the next two cells where you create the function defination and perform function call to check status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition to check the progress of the bulk import job\n",
    "def check_bulk_import_progress(job_id):\n",
    "    while True:\n",
    "        res = twinmakerclient.get_metadata_transfer_job(metadataTransferJobId=job_id)\n",
    "        state = res[\"status\"][\"state\"]\n",
    "        if state in ('RUNNING', 'COMPLETED'):\n",
    "            try:\n",
    "                progress = res[\"progress\"]\n",
    "                print(f'Status: {state} | Total: {progress[\"totalCount\"]}, Suceeded: {progress[\"succeededCount\"]}, Skipped: {progress[\"skippedCount\"]}, Failed: {progress[\"failedCount\"]}')                \n",
    "            except:\n",
    "                print(f'Status: {state}')\n",
    "        elif state == 'ERROR':\n",
    "            print(f'Status: {state} | Report URL: {res[\"reportUrl\"]}')\n",
    "            break\n",
    "        else:\n",
    "            print(f'Status: {state}')\n",
    "        if state == 'COMPLETED': break\n",
    "        time.sleep(20) # Check status every 20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call to check status of metadata bulk import job\n",
    "check_bulk_import_progress(import_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<span style=\"font-size: 1.5em;\">üí°</span> You can also look in the AWS IoT SiteWise Console as the assets are being created live!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Deploy Shopfloor Connectivity framework to send data to AWS IoT SiteWise\n",
    "\n",
    "Let's now revisit SFC that got introduced in the previous chapter.\n",
    "\n",
    "SFC requires two main types of configurations:\n",
    "1. Source configurations: Define how to collect data from industrial equipment (e.g., protocols like SIEMENS S7, Ethernet/IP, MQTT)\n",
    "2. Target configurations: Specify how to send data to AWS services (e.g., AWS IoT SiteWise, Amazon Timestream, Amazon S3)\n",
    "\n",
    "[It can be deployed in two modes](https://github.com/aws-samples/shopfloor-connectivity/blob/mainline/docs/README.md#in-process-and-ipc-deployment-models): **in-Process** and **Inter-Process-Communication (IPC)**.\n",
    "In this workshop we are using the **In-Process** mode as it within a single, unified process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create SFC configuration based on TIA export files\n",
    "\n",
    "Two Python scripts are used to create a valid SFC source and target config package:\n",
    "\n",
    "1. `scripts/create_sfc_config_files.py`\n",
    "2. `scripts/sfc/s7tia2sfc.py`\n",
    "\n",
    "These scripts use methods to extract device and data block information from the TIA exports. The extracted data is then converted into a JSON dictionary format that can be used by the SFC framework.\n",
    "The resulting SFC config package is stored in the `imports/sfc` folder.\n",
    "\n",
    "The next step creates JSON config files and executables for running SFC locally. These files are then moved to the ```C:/``` drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "os.chdir('C://Users//Administrator//Documents//jupyter-notebook//scripts')\n",
    "!py create_sfc_config_files.py --region {aws_region}\n",
    "shutil.copytree(r\"C:\\Users\\Administrator\\Documents\\jupyter-notebook\\imports\\sfc\\CarFactory\", r\"C:\\CarFactory\", dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Install and execute the SFC\n",
    "\n",
    "Next, we will execute the SFC installer. This will downloads protocol adapters and target adapters from the SFC GitHub releases. These are necessary components for the SFC execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!powershell.exe -Command \"Set-Location -Path C:\\CarFactory ; ./sfc-standalone-install.bat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now run the SFC. This process will ingest all source data into [disassociated Sitewise streams](https://docs.aws.amazon.com/iot-sitewise/latest/userguide/manage-data-streams-method.html). \n",
    "As the SFC executes, watch for indicators of successful data transmission. You should see logs or messages confirming that data is being sent to AWS IoT SiteWise. Disassociated streams allow for rapid data ingestion without requiring a predefined asset structure. \n",
    "This approach enables us to collect data quickly and explore it before finalizing our asset models.\n",
    "\n",
    "**Important Note:** The following code will initiate a PowerShell window to run the SFC component. This window must remain open for continuous data ingestion. Monitor the PowerShell window for real-time ingestion status and any potential error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C://CarFactory')\n",
    "!powershell.exe -Command \"Set-Location -Path C:\\CarFactory ; Start-process powershell.exe -ArgumentList 'C:\\CarFactory\\sfc-standalone-runner.bat'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to implement a verified AWS IoT SiteWise target configuration for SFC. This will ingest the near real-time data to the created assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copyfile(r'C:\\Users\\Administrator\\Documents\\jupyter-notebook\\include_generated_swtarget.json', r\"C:\\CarFactory\\include_generated_swtarget.json\")\n",
    "# IMPORTANT: check region attribute in C:\\CarFactory\\include_generated_swtarget.json - defaults to us-west-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the workshop's guided steps to navigate to the AWS IoT SiteWise console and monitor the live data ingestion process under the asset's ```Latest Value``` area. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<span style=\"font-size: 1.5em;\">&#x1F3C6;</span><b>Congratulations!</b>\n",
    "You now have a Unified Namespace setup in the Cloud. Now let's visualise it using AWS IoT SiteWise Monitor.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. üìà Visualisation of data in Unified Namespace using AWS IoT Sitewise Monitor\n",
    "\n",
    "AWS IoT SiteWise Monitor is a feature of AWS IoT SiteWise that provides portals in the form of managed web applications. You can use these applications to view and share your operational data and alarms. You can see data from your processes, devices, and equipment that are connected to AWS IoT SiteWise. Domain experts, such as process engineers, can use these portals to quickly get insights into their operational data to understand device and equipment behavior. They can use these insights to improve efficiency of devices, processes, or equipment and innovate on new initiatives. Operators can monitor data with alarms and respond to alarms when devices and equipment perform sub-optimally.\n",
    "\n",
    "We will now create AWS Sitewise Monitor Portal to visualise data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Create AWS IoT Sitewise Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portal_Name = 'reInvent Car Factory'                                    # Can be changed per liking\n",
    "email_id = 'abcde@gmail.com'                                            # Provide your personal email id\n",
    "\n",
    "if check_if_portal_exists(portal_Name):\n",
    "    print(f\"A portal with the name '{portal_Name}' already exists.\")\n",
    "    \n",
    "else:\n",
    "    portal_meta_data = create_visualisation(portal_Name,email_id)\n",
    "    %store portal_meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<span style=\"font-size: 1.5em;\">üìã</span> Now follow the instruction in the workshop to create dashboards and visualise KPIs of the factory that you have created.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \tü¶æ GenerativeAI Playground (Optional)\n",
    "\n",
    "Now you should have an understanding of how AWS IoT SiteWise metadata bulk imports work, now let's try to execute the same steps as before with acutal configration files and schema that were generated by Amazon Bedrock in the previous Notebook. In the first step you had created the complete hierarchy, we will reuse Asset Models, Properties and Metrics\n",
    "\n",
    "<div class=\"alert alert-block alert-info padding-left: 2em;\">\n",
    "<span style=\"font-size: 1.5em;\">‚è±Ô∏è</span>  Each metadata bulk operation execution takes 2 mins on average. So, please be patient and make sure to check the AWS Console after every execution to see the results. Please refresh your browser if needed\n",
    "</div>\n",
    "\n",
    "#### 4.1 Initialise your playground\n",
    "Before we start lets delete assets and the hierarchy definition from the previous steps, so that we can create it new in the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sitewise_helpers import *\n",
    "delete_child_assets(classic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-left: 2em;\">&#x2611; All Cell Units or child assets would be deleted</div>\n",
    "\n",
    "#### 4.2 Generate GenAI AWS IoT SiteWise assets\n",
    "Next, using the asset schema JSON <span style=\"font-family: monospace;\"> genai_sitewise_assets_schema.json</span> created by Amazon Bedrock in the last Notebook, execute the metadata bulk import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitewise_schema = \"genai_sitewise_assets_schema.json\"\n",
    "import_job_id = meta_data_import(sitewise_schema)\n",
    "\n",
    "check_bulk_import_progress(import_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-left: 2em;\">&#x2611; New GenAI Cell Units or child assets are created</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Generate GenAI AWS IoT SiteWise assets hieararchy\n",
    "\n",
    "You will see new assets are created with <span style=\"font-family: monospace;\">GenAI</span> prefix as expected. Next, execute the next cell to initiate another bulk import to define hierarchies for the assets that you have created and this time with the config file <span style=\"font-family: monospace;\">genai_sitewise_hierarchy_schema.json</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitewise_schema = \"genai_sitewise_hierarchy_schema.json\"\n",
    "import_job_id = meta_data_import(sitewise_schema)\n",
    "\n",
    "check_bulk_import_progress(import_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-left: 2em;\">&#x2611; New GenAI asset hierarchies are created</div>\n",
    "\n",
    "#### 4.4 Configure SFC for GenAI assets\n",
    "Now we will **manually** override the previous AWS IoT SiteWise config for SFC with the configuration that was generated by Amazon Bedrock. For this we will use the config file <span style=\"font-family: monospace;\"> genai_sfc_sitewise_target_conf.json</span>. SFC will update config automatically during runtime.\n",
    "\n",
    "You should see live data on AWS IoT SiteWise Console and Monitor. Also observe the logs in the powershell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copyfile(r'C:\\Users\\Administrator\\Documents\\jupyter-notebook\\genai_sfc_sitewise_target_conf.json', r\"C:\\CarFactory\\include_generated_swtarget.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-left: 2em;\">&#x2611; SFC configured and data is streamed to AWS IoT Sitewise</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<p align=\"center\">\n",
    "        <span style=\"font-size: 1.5em;\">üèÅ</span><em> You have now completed this Workshop! Please don't forget to cleanup the resources. Check the worshop documentation as well <em><span style=\"font-size: 1.5em;\">üèÅ</span>\n",
    "    </p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπCleanup\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<span style=\"font-size: 1.5em;\">&#x2757;</span> Excecute the Clean-up cells sequentially only at the end of the workshop. if you execute it any earlier you will have to start over from the beginning of this notebook\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deletes all Sitewise resources you have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sitewise_helpers import *\n",
    "delete_all_sitewise_elements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Deletes the AWS IoT Sitewise monitor you created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sitewise_helpers import *\n",
    "%store -r portal_meta_data\n",
    "delete_visualisation(portal_meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Deletes all contents in the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_all_objects(bucketname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
